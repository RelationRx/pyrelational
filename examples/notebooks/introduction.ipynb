{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart with the active learning module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Active learning]( https://en.wikipedia.org/wiki/Active_learning_(machine_learning) ) is a method that aims to collect and labelled new data in order to improve the machine learning model. Based on a predefined heuristic strategy, a certain number of data will be annotated and used to re-train the model. \n",
    "In pyrelational, we use: \n",
    "- an active learning ``strategy``, that query new data points based on specific selection criterion;\n",
    "- a ``model manager`` that takes in input an uninstantiated ML model and a set of arguments (ie: the number of epochs) used for training;\n",
    "- a ``data_manager`` that will update, after each query, the pool of labelled and unlabelled data; \n",
    "- an ``oracle``, at the interface between the data manager and the strategy, it gives the user the ability to access the queried data and manually annotate it with external tools. The oracle is optional; \n",
    "- a ``pipeline`` that aims to manage the strategy, the model and the data manager together."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "We will use the sklearn [digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) where each datapoint is a 8x8 image of a digit that we aim to classify with a neural network.\n",
    "\n",
    "We are defining a data manager that will update the pool of labelled data used to train the model. The validation set and the test set are fixed, and they will always remained unchanged. In the following example, we have 9000 unlabelled images, which we aim to query, based on a specific strategy, and annotate, to improve the model performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from pyrelational.data_managers import DataManager\n",
    "\n",
    "# creating the dataset with pytorch\n",
    "dataset = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "train_ds, val_ds, test_ds = torch.utils.data.random_split(dataset, [50000, 5000, 5000])\n",
    "train_indices = train_ds.indices\n",
    "val_indices = val_ds.indices\n",
    "test_indices = test_ds.indices\n",
    "\n",
    "# creating the data manager\n",
    "data_manager = DataManager(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    validation_indices=val_indices,\n",
    "    test_indices=test_indices,\n",
    "    loader_batch_size=1000,\n",
    "    label_attr=\"targets\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model manager\n",
    "\n",
    "The model manager here is build with the [Pytorch Lightning module](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html). \n",
    "It needs three inputs: \n",
    "- a `model class` that contains the core structure of the model and can contain some hyperparameters such as the number of layers or the dropout rate.\n",
    "- a `model configuration` dictionary that contains the values for the hyperparameters. It can be empty if no parameters are defined.\n",
    "- a `trainer configuration` dictionary with all the parameters needed for training, written in a pytorch lightning fashion. The default dictionnary can be inspected in the `models/lightning_model.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import LightningModule\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class MnistClassification(LightningModule):\n",
    "    \"\"\"Custom module for a simple convnet Classification\"\"\"\n",
    "\n",
    "    def __init__(self, dropout=0):\n",
    "        super(MnistClassification, self).__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 256)\n",
    "        self.layer_3 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.dropout(self.layer_1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(self.layer_2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(self.layer_3(x))\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        # compute accuracy\n",
    "        _, y_pred = torch.max(logits.data, 1)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        self.log(\"test_accuracy\", accuracy)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrelational.model_managers import LightningMCDropoutModelManager\n",
    "\n",
    "\n",
    "model_manager = LightningMCDropoutModelManager(\n",
    "    model_class=MnistClassification, \n",
    "    model_config={\"dropout\": 0.2}, \n",
    "    trainer_config={\"epochs\": 4})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The query strategy and the active learning loop\n",
    "\n",
    "Using more labelled data for training improves the model performances. Yet, labelling data can be time-consuming and some data may be more influential. The idea is to query the most informative data that aim to be annotated. The informativeness of the data depends on the strategy used. In this example, we are considering four different strategies designed for a classification task: \n",
    "\n",
    "- `least confidence strategy` aim to query samples whose predictions are the most uncertain;\n",
    "- `marginal confidence strategy` computes the difference between the top and second top prediction: the lower is this difference, the highest is the score;\n",
    "- `ratio confidence strategy` is similar to the marginal confidence strategy except that the score is computed as a ratio between the top and the second top predictions;\n",
    "- `entropy classification strategy` returns the Shannon entropy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "from pyrelational.pipeline import Pipeline\n",
    "from pyrelational.strategies.classification import (\n",
    "    LeastConfidenceStrategy,\n",
    "    MarginalConfidenceStrategy,\n",
    "    RatioConfidenceStrategy,\n",
    "    EntropyClassificationStrategy,\n",
    ")\n",
    "\n",
    "query = dict()\n",
    "strategies = [LeastConfidenceStrategy,\n",
    "                 MarginalConfidenceStrategy, \n",
    "                 RatioConfidenceStrategy, \n",
    "                 EntropyClassificationStrategy]\n",
    "\n",
    "for strategy in strategies:\n",
    "    # the data manager is reinitialized for each strategy\n",
    "    data_manager = DataManager(\n",
    "        dataset=dataset,\n",
    "        train_indices=train_indices,\n",
    "        validation_indices=val_indices,\n",
    "        test_indices=test_indices,\n",
    "        loader_batch_size=10000,\n",
    "        label_attr=\"targets\",\n",
    "    )\n",
    "    pipeline = Pipeline(data_manager=data_manager, model_manager=model_manager, strategy=strategy())\n",
    "\n",
    "    # we will annotate 10000 points step by step until there is no more unlabelled training data\n",
    "    # The training pool consists of 50000 points, so we will annotate all the points in 9 runs\n",
    "    pipeline.run(num_annotate=10000)\n",
    "    query[strategy.__name__] = pipeline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a specific strategy: after each iteration, the test accuracy should increase. More metrics can be stored in the pipeline, as long as they are logged in the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print performance after each iteration for one strategy\n",
    "query['MarginalConfidenceStrategy'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for strategy in strategies :\n",
    "    df = query[strategy.__name__].summary()\n",
    "    plt.plot(df['test_accuracy'], label=strategy.__name__)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of iteration')\n",
    "    plt.title('Accuracy for different strategies')\n",
    "plt.show()\n",
    "\n",
    "for strategy in strategies :\n",
    "    df = query[strategy.__name__].summary()\n",
    "    plt.plot(df['test_loss'], label=strategy.__name__)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of iteration')\n",
    "    plt.title('Loss for different strategies')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrelational",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a560e7bfbcc730b574354bbb352b8f1c29db364fabf39cac4454c322ba4541fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
